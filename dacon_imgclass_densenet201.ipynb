{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80772f5f",
   "metadata": {},
   "source": [
    "# DenseNet201 기반 이미지 분류 (10-Fold CV + 증강)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 라이브러리 버전\n",
    "# numpy : 2.2.4\n",
    "# pandas : 2.2.3\n",
    "# torch : 2.6.8+cu124\n",
    "# torchvision : 0.21.0+cu124\n",
    "# timm : 1.0.15\n",
    "# scikit-learn : 1.6.1\n",
    "# tqdm : 4.67.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 무시 설정 및 필수 라이브러리 임포트\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 경고 메시지를 무시하여 출력 깔끔하게 유지\n",
    "\n",
    "import numpy as np                  # 수치 연산을 위한 NumPy\n",
    "import pandas as pd                 # 데이터 처리 및 CSV 입출력용 pandas\n",
    "\n",
    "import torch                        # PyTorch 메인 패키지\n",
    "import torch.nn as nn               # 신경망 레이어 및 손실 함수\n",
    "import torch.optim as optim         # 최적화 알고리즘\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset  # 데이터셋, 로더 유틸리티\n",
    "\n",
    "from torchvision.transforms import Compose, ToPILImage, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomVerticalFlip\n",
    "# 이미지 전처리 및 증강을 위한 torchvision.transforms\n",
    "\n",
    "import timm                         # PyTorch 모델 라이브러리\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder            # 레이블 인코딩\n",
    "from sklearn.model_selection import StratifiedKFold       # 층화 K-Fold 교차 검증\n",
    "\n",
    "from tqdm import tqdm              # 진행 상황 표시용 tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcdd55b",
   "metadata": {},
   "source": [
    "## 1. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c522047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 하이퍼파라미터 정의\n",
    "N_EPOCHS = 100     # 에폭 수\n",
    "BATCH_SIZE = 8     # 배치 크기\n",
    "LR = 5e-5          # 학습률\n",
    "N_FOLDS = 10       # 교차 검증 폴드 수\n",
    "SEED = 42          # 랜덤 시드 고정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a27472",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드 및 라벨 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일에서 학습/테스트 데이터 로드\n",
    "train = pd.read_csv(\"/data/train.csv\")  # 학습 데이터\n",
    "test = pd.read_csv(\"/data/test.csv\")    # 테스트 데이터\n",
    "\n",
    "# 문자열 레이블을 숫자로 변환\n",
    "encoder = LabelEncoder()\n",
    "train['label'] = encoder.fit_transform(train['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f92ef4",
   "metadata": {},
   "source": [
    "## 3. CustomDataset 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, pixel_df, label_df=None, transform=None):\n",
    "        # DataFrame을 인덱스 초기화하여 깔끔하게 관리\n",
    "        self.pixel_df = pixel_df.reset_index(drop=True)\n",
    "        self.label_df = label_df.reset_index(drop=True) if label_df is not None else None\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋 크기를 반환\n",
    "        return len(self.pixel_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 픽셀 데이터를 32x32 이미지 배열로 변환\n",
    "        image = self.pixel_df.iloc[idx].values.astype(np.uint8).reshape(32, 32)\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # (1, 32, 32) 형태로 변환\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Transform(증강/전처리) 적용\n",
    "        if self.label_df is not None:\n",
    "            label = torch.tensor(self.label_df.iloc[idx], dtype=torch.long)\n",
    "            return image, label\n",
    "        else:\n",
    "            # 테스트 시에는 레이블이 없으므로 이미지만 반환\n",
    "            return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933767a6",
   "metadata": {},
   "source": [
    "## 4. 데이터 증강 및 전처리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 증강: 좌우/상하 뒤집기 + 크기 조정 + 정규화\n",
    "train_transform = Compose([\n",
    "    ToPILImage(),                         # 텐서를 PIL 이미지로 변환\n",
    "    Resize((224, 224)),                   # 모델 입력 크기로 Resize\n",
    "    RandomHorizontalFlip(p=0.5),          # 랜덤 좌우 뒤집기\n",
    "    RandomVerticalFlip(p=0.5),            # 랜덤 상하 뒤집기\n",
    "    ToTensor(),                           # 다시 텐서로 변환\n",
    "    Normalize(mean=[0.5], std=[0.5]),     # 정규화\n",
    "])\n",
    "\n",
    "# 검증/테스트용 전처리: 증강 없이 Resize + 정규화\n",
    "val_transform = Compose([\n",
    "    ToPILImage(),\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb0089e",
   "metadata": {},
   "source": [
    "## 5. Device 설정 및 DataLoader 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 여부 판단\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# DataLoader 공통 파라미터\n",
    "loader_params = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 0,   # 환경에 따라 worker 수 조정\n",
    "    'pin_memory': True  # GPU 메모리 활용 최적화\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea036f86",
   "metadata": {},
   "source": [
    "## 6. 10-Fold 교차 검증 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold로 폴드 분할 객체 생성\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "all_fold_preds = []  # 폴드별 테스트 예측 저장\n",
    "fold_idx = 1\n",
    "\n",
    "for train_idx, valid_idx in skf.split(train.iloc[:, 2:], train['label']):\n",
    "    print(f\"--- Fold {fold_idx} 시작 ---\")\n",
    "    \n",
    "    # 학습/검증 데이터셋 분리\n",
    "    train_dataset = CustomDataset(train.iloc[train_idx, 2:], train.iloc[train_idx, 1], transform=train_transform)\n",
    "    valid_dataset = CustomDataset(train.iloc[valid_idx, 2:], train.iloc[valid_idx, 1], transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, **loader_params)\n",
    "    valid_loader = DataLoader(valid_dataset, shuffle=False, **loader_params)\n",
    "    \n",
    "    # 모델 초기화: DenseNet201, 입력 채널 1, 클래스 수 10\n",
    "    model = timm.create_model(\"densenet201\", pretrained=False, num_classes=10, in_chans=1).to(device)\n",
    "    \n",
    "    # 손실 함수 및 최적화 함수\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    # 에폭 반복\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(f\"Fold {fold_idx} Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "        \n",
    "        # ----- 학습 단계 -----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # ----- 검증 단계 -----\n",
    "        model.eval()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(valid_loader, desc=\"Validation\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (preds == labels).sum().item()\n",
    "        val_loss = running_loss / len(valid_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "        \n",
    "        # 최적 모델 상태 저장\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # 최적 가중치 로드\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"Fold {fold_idx} 완료. 최적 모델 로드.\")\n",
    "    \n",
    "    # 테스트 데이터 예측\n",
    "    test_loader = DataLoader(CustomDataset(test.iloc[:, 1:], transform=val_transform), shuffle=False, **loader_params)\n",
    "    fold_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader, desc=\"Inference\", leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            fold_preds.append(outputs.cpu().numpy())\n",
    "    all_fold_preds.append(np.concatenate(fold_preds, axis=0))\n",
    "    \n",
    "    fold_idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ee01f",
   "metadata": {},
   "source": [
    "## 7. 예측 평균 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34615c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드별 예측 결과 평균\n",
    "avg_test_preds = np.mean(np.array(all_fold_preds), axis=0)\n",
    "pred_indices = np.argmax(avg_test_preds, axis=1)\n",
    "\n",
    "# 숫자 레이블을 원본 문자열 레이블로 변환\n",
    "pred_labels = encoder.inverse_transform(pred_indices)\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.read_csv(\"/data/sample_submission.csv\")\n",
    "submission['label'] = pred_labels\n",
    "submission.to_csv(\"/data/submission_dense201_cv_aug.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"File saved\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
